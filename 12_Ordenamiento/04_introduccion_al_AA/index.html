<!DOCTYPE html>
<html lang="es">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://matiaslopez.github.io/python_unsam_test/12_Ordenamiento/04_introduccion_al_AA/">
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>04 introduccion al AA - Programación en Python</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-ABC123"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-ABC123');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-light bg-light">
            <div class="container">
                <a class="navbar-brand" href="../..">Programación en Python</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../.." class="nav-link">Inicio</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Unidades <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../01_Introduccion/00_Resumen/" class="dropdown-item">01 - Introducción</a>
</li>
                                    
<li>
    <a href="../../02_Estructuras_y_Funciones/00_Resumen/" class="dropdown-item">02 - Estructuras y funciones</a>
</li>
                                    
<li>
    <a href="../../03_Datos/00_Resumen/" class="dropdown-item">03 - Trabajando con datos</a>
</li>
                                    
<li>
    <a href="../../04_Listas_y_Listas/00_Resumen/" class="dropdown-item">04 - Algoritmos sobre listas y comprensión de listas</a>
</li>
                                    
<li>
    <a href="../../05_Random_Plt_Dbg/00_Resumen/" class="dropdown-item">05 - Aleatoridad</a>
</li>
                                    
<li>
    <a href="../../06_Organizacion_y_Complejidad/00_Resumen/" class="dropdown-item">06 - Complejidad y Organización de programas</a>
</li>
                                    
<li>
    <a href="../../07_Plt_Especificacion_y_Documentacion/00_Resumen/" class="dropdown-item">07 - Diseño, especificación, documentación y estilo</a>
</li>
                                    
<li>
    <a href="../../08_Fechas_Carpetas_y_Pandas/00_Resumen/" class="dropdown-item">08 - Fechas, Carpetas y Pandas</a>
</li>
                                    
<li>
    <a href="../../09_Clases_y_Objetos/00_Resumen/" class="dropdown-item">09 - Clases y objetos</a>
</li>
                                    
<li>
    <a href="../../10_Generadores_e_Iteradores/00_Resumen/" class="dropdown-item">10 - Generadores e iteradores</a>
</li>
                                    
<li>
    <a href="../../11_Recursion/00_Resumen/" class="dropdown-item">11 - Recursión y regresión</a>
</li>
                                    
<li>
    <a href="../00_Resumen/" class="dropdown-item">12 - Ordenamiento</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Buscar
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Tabla de contenidos">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#124-algoritmos-de-clasificacion-supervisada" class="nav-link">12.4 Algoritmos de clasificación supervisada</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#veamos-los-datos" class="nav-link">Veamos los datos</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#visualizacion-de-los-datos" class="nav-link">Visualización de los datos</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#training-y-testing" class="nav-link">Training y testing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#modelar" class="nav-link">Modelar</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#evaluacion-del-modelo" class="nav-link">Evaluación del modelo</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#pasando-en-limpio-todo" class="nav-link">Pasando en limpio todo</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#ejercicios" class="nav-link">Ejercicios:</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><a href="../Contenidos.md">Contenidos</a> | <a href="../03_Divide_and_Conquer/">Anterior (3 Divide y reinarás)</a> | <a href="../05_Cierre/">Próximo (5 Cierre de la clase de Ordenamiento)</a></p>
<h1 id="124-algoritmos-de-clasificacion-supervisada">12.4 Algoritmos de clasificación supervisada</h1>
<p>Para esta sección tenemos este <a href="https://youtu.be/ygxoVQNRqs8">video introductorio</a>.</p>
<p>En esta sección veremos un algoritmo de clasificación. Un problema de clasificación es un problema en el que tenemos algunas clases fijas (en nuestro ejemplo serán tres tipos de flores) y algunos atributos (medidas de los pétalos y sépalos, en nuestro ejemplo) a partir de los cuales queremos <em>inferir</em> la clase. Típicamente el algoritmo de clasificación se <em>entrena</em> con alguna parte de los datos para que <em>aprenda</em> y luego se <em>evalúa</em> cuán bien aprendió con el resto de los datos. Para esto hace falta tener un conjunto de datos <em>etiquetados</em> (es decir, con la clase bien definida). Luego, si funciona bien, el algoritmo podrá usarse para etiquetar nuevos datos de los que no se conoce la clase.</p>
<p>En esta sección nos concentraremos en el entrenamiento y la evaluación de los algoritmos.</p>
<p>Trabajaremos con la librería sklearn de python que está diseñada para realizar tareas de aprendizaje automático. La misma trae algunos conjuntos de datos de ejemplo. Trabajaremos con el clásico ejemplo de <strong>Clasificación de Especies de flores Iris</strong> según medidas del pétalo y el sépalo.</p>
<p><img alt="sepal_petal" src="../iris_petal_sepal.png" /></p>
<h2 id="veamos-los-datos">Veamos los datos</h2>
<pre><code class="language-python">from sklearn.datasets import load_iris
iris_dataset = load_iris()
</code></pre>
<p>Este dataset trae una serie de datos medidos de los pétalos y sépalos de 150 flores Iris y su clasificación en tres especies (setosa, versicolor y virginica). La idea es usar algunos de los datos de flores para entrenar un algoritmo y ver si podemos deducir la especie de las otras flores (no clasificadas) usando solo sus medidas.</p>
<p>El dataset es un diccionario con diferentes datos. Esencialmente en "data" tiene un array con las medidas de ancho y largo de pétalo y sépalo (atributos, o "features" en inglés) de 150 flores  y en "target" tiene un numero (0, 1 ó 2) que representa la especie de estas flores. Veamos un poco la estructura de estos datos. El diccionario tiene las siguientes claves:</p>
<pre><code class="language-python">&gt;&gt;&gt; print(&quot;Claves del diccionario iris_dataset:\n&quot;, iris_dataset.keys())
Claves del diccionario iris_dataset:
 dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])
</code></pre>
<p>Las flores se clasifican en tres:</p>
<pre><code class="language-python">&gt;&gt;&gt; print(&quot;Target names:&quot;, iris_dataset['target_names'])
    Target names: ['setosa' 'versicolor' 'virginica']
</code></pre>
<p>Y los atributos son cuatro por cada flor:</p>
<pre><code class="language-python">&gt;&gt;&gt; print(&quot;Feature names:\n&quot;, iris_dataset['feature_names'])
    Feature names:
     ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
</code></pre>
<p>Son 150 flores etiquetadas, con cuatro atributos cada una, en un array de numpy. Las etiquetas son 0, 1 y 2 y se guardan también en un array:</p>
<pre><code class="language-python">&gt;&gt;&gt; print(&quot;Type of data:&quot;, type(iris_dataset['data']))
    Type of data: &lt;class 'numpy.ndarray'&gt;

&gt;&gt;&gt; print(&quot;Shape of data:&quot;, iris_dataset['data'].shape)
    Shape of data: (150, 4)

&gt;&gt;&gt; print(&quot;First five rows of data:\n&quot;, iris_dataset['data'][:5])
    First five rows of data:
     [[5.1 3.5 1.4 0.2]
     [4.9 3.  1.4 0.2]
     [4.7 3.2 1.3 0.2]
     [4.6 3.1 1.5 0.2]
     [5.  3.6 1.4 0.2]]

&gt;&gt;&gt; print(&quot;Type of target:&quot;, type(iris_dataset['target']))
    Type of target: &lt;class 'numpy.ndarray'&gt;

&gt;&gt;&gt; print(&quot;Shape of target:&quot;, iris_dataset['target'].shape)
    Shape of target: (150,)

&gt;&gt;&gt; print(&quot;Target:\n&quot;, iris_dataset['target'])
    Target:
     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
     1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
     2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
     2 2]
</code></pre>
<h2 id="visualizacion-de-los-datos">Visualización de los datos</h2>
<p>Hagamos primero unos gráficos exploratorios para ver los datos y entender las correlaciones entre los atributos, usando un color diferente para cada especie de flor.</p>
<pre><code class="language-python">import pandas as pd
# creamos un dataframe de los datos de flores
# etiquetamos las columnas usando las cadenas de iris_dataset.feature_names
iris_dataframe = pd.DataFrame(iris_dataset['data'], columns = iris_dataset.feature_names)
# y hacemos una matriz de gráficos de dispersión, asignando colores según la especie
pd.plotting.scatter_matrix(iris_dataframe, c = iris_dataset['target'], figsize = (15, 15), marker = 'o', hist_kwds = {'bins': 20}, s = 60, alpha = 0.8)
</code></pre>
<p><img alt="png" src="../output_27_1.png" /></p>
<p>Notamos que una de las especies se distingue más fácilmente de las otras dos, mientras que las otras presentan cierta superposición. </p>
<h3 id="ejercicio-1210-seaborn">Ejercicio 12.10: Seaborn</h3>
<p>Repetí el gráfico anterior pero usando seaborn en lugar de pandas para graficar, y guardá el código correspondiente en un archivo <code>iris_seaborn.py</code> para entregarlo.</p>
<p><em>Sugerencia:</em> Usando <code>iris_dataframe['target'] = iris_dataset['target']</code>, agregá al DataFrame el atributo <code>target</code> de cada flor para poder hacer un <code>sns.pairplot()</code> seteando <code>hue</code> sobre las especies de iris.</p>
<h2 id="training-y-testing">Training y testing</h2>
<p>Como dijimos antes, vamos a entrenar un algoritmo y luego a evaluar su capacidad de clasificar. Para evitar sesgos y sobreajustes tenemos que partir al conjunto de datos en dos:</p>
<ul>
<li>una parte de los datos (training) será de entrenamiento del algoritmo y</li>
<li>otra parte (testing) será usada para la evaluación.</li>
</ul>
<p>La librería sklearn trae funciones que hacen esta separación (split) de forma aleatoria, como se ve a continuación (en este caso fijamos una semilla con <code>random_state = 0</code>, luego la sacaremos). Obviamente separamos tanto los atributos (features) como su clase (target). En este caso usaremos el 75% de los datos para entrenar y el 25% restante para evaluar.</p>
<pre><code class="language-python">from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    iris_dataset['data'], iris_dataset['target'], random_state = 0)
</code></pre>
<pre><code class="language-python">&gt;&gt;&gt; print(&quot;X_train shape:&quot;, X_train.shape)
&gt;&gt;&gt; print(&quot;y_train shape:&quot;, y_train.shape)
    X_train shape: (112, 4)
    y_train shape: (112,)

&gt;&gt;&gt; print(&quot;X_test shape:&quot;, X_test.shape)
&gt;&gt;&gt; print(&quot;y_test shape:&quot;, y_test.shape)
    X_test shape: (38, 4)
    y_test shape: (38,)
</code></pre>
<h2 id="modelar">Modelar</h2>
<p>Ahora vamos a construir nuestro primer modelo. Usaremos un algoritmo sencillo que se llama de "vecinos más cercanos" (K-nearest neighbors_ en inglés, ver <a href="https://es.wikipedia.org/wiki/K_vecinos_m%C3%A1s_pr%C3%B3ximos">wikipedia</a>). Lo entrenaremos con los datos de entrenamiento y al consultarle por un nuevo dato (de los de testing) lo que hará el algoritmo es buscar al dato de entrenamiento más cercano en el espacio de atributos y asignarle al nuevo dato la especie de esa flor. En otras palabras: cuando le preguntemos por la especie de una flor nueva va a contestarnos con la especie de la flor "más cercana" en el espacio de atributos (ancho y largo del pétalo y el sépalo).</p>
<p>De esta forma el espacio de atributos queda dividido en regiones a las que se asignará cada especie. En el siguiente gráfico puede verse una partición de un espacio de dos atributos y tres clases considerando un vecino más cercano (k=1) y entrenado con los datos del gráfico:</p>
<p><img alt="areas_knn" src="../Map1NN.png" /></p>
<p>A un nuevo punto en este plano el clasificador así entrenado le asignará la clase correspondiente al color de fondo, que coincide con la clase del vecino más cercano.</p>
<p>Creamos una instancia de la clase <code>KNeighborsClassifier</code></p>
<pre><code class="language-python">from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 1)
</code></pre>
<p>Y la entrenamos con los datos de entrenamiento</p>
<pre><code class="language-python">knn.fit(X_train, y_train)
</code></pre>
<p>Listo, tenemos el clasificador entrenado. Ahora lo podemos usar para predecir la clase de una nueva flor a partir de sus cuatro medidas:</p>
<pre><code class="language-python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X_new = np.array([[5, 2.9, 1, 0.2]])
&gt;&gt;&gt; print(&quot;X_new.shape:&quot;, X_new.shape)
    X_new.shape: (1, 4)
</code></pre>
<p>Grafiquemos este nuevo punto en rojo y veamos su relación con los datos de entrenamiento en dos de los atributos.</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
plt.scatter(X_train[:, 1], X_train[:, 3], c = y_train)
plt.scatter(X_new[:, 1], X_new[:, 3], c = 'red')
</code></pre>
<p><img alt="png" src="../output_36_1.png" /></p>
<p>Acá se ve que el punto rojo esta cerca de la clase "setosa". Utilicemos ahora el algoritmo knn entrenado para clasificar el punto <code>X_new</code>:</p>
<pre><code class="language-python">&gt;&gt;&gt; prediction = knn.predict(X_new)
&gt;&gt;&gt; print(&quot;Predicción:&quot;, prediction)
&gt;&gt;&gt; print(&quot;Nombre de la Especie Predicha:&quot;,
       iris_dataset['target_names'][prediction])
    Predicción: [0]
    Nombre de la Especie Predicha: ['setosa']
</code></pre>
<h2 id="evaluacion-del-modelo">Evaluación del modelo</h2>
<p>Finalmente, usemos el 25% de los datos etiquetados que nos guardamos para evaluar cuán bien funciona nuestro clasificador.</p>
<pre><code class="language-python">&gt;&gt;&gt; y_pred = knn.predict(X_test)
&gt;&gt;&gt; print(&quot;Predicciones para el conjunto de Test:\n&quot;, y_pred)
&gt;&gt;&gt; print(&quot;Etiquetas originales de este conjunto:\n&quot;, y_test)
    Predicciones para el conjunto de Test:
     [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0
     2]
    Etiquetas originales de este conjjuto:
     [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0
     1]
</code></pre>
<p>Se ve que coinciden todos salvo el último. Podemos medir el éxito calculando la fracción de clasificaciones bien hechas (calculamos el promedio de "1 si está bien, 0 si está mal"):</p>
<pre><code class="language-python">&gt;&gt;&gt; print(y_pred == y_test)
&gt;&gt;&gt; print(&quot;Test set score: {:.2f}&quot;.format(np.mean(y_pred == y_test)))
    [ True  True  True  True  True  True  True  True  True  True  True  True
      True  True  True  True  True  True  True  True  True  True  True  True
      True  True  True  True  True  True  True  True  True  True  True  True
      True False]
    Test set score: 0.97
</code></pre>
<p>O, directamente, usando el método <code>score</code> que ya viene en el clasificador:</p>
<pre><code class="language-python">&gt;&gt;&gt; print(&quot;Test set score: {:.2f}&quot;.format(knn.score(X_test, y_test)))
    Test set score: 0.97
</code></pre>
<h2 id="pasando-en-limpio-todo">Pasando en limpio todo</h2>
<p>Lo que hicimos hasta ahora fue:</p>
<pre><code>1) Separar los datos en dos conjuntos: train y test.
2) Definir un clasificador knn y entrenarlo con los datos de training.
3) Evaluar el clasificador con los datos de testing.
</code></pre>
<pre><code class="language-python">X_train, X_test, y_train, y_test = train_test_split(
    iris_dataset['data'], iris_dataset['target'])

knn = KNeighborsClassifier(n_neighbors = 1)
knn.fit(X_train, y_train)

print(&quot;Test set score: {:.2f}&quot;.format(knn.score(X_test, y_test)))
</code></pre>
<p>Observá que en este último fragmento de código el split en test y train es aleatorio, y va a dar resultados (scores) diferentes cada vez que lo corramos.</p>
<h2 id="ejercicios">Ejercicios:</h2>
<h3 id="ejercicio-1211">Ejercicio 12.11:</h3>
<p>Leé sobre los <a href="https://es.wikipedia.org/wiki/Aprendizaje_basado_en_%C3%A1rboles_de_decisi%C3%B3n">clasificadores basados en arboles de decisión</a> y luego usá el objeto clasificador <code>clf</code> (definido a continuación) como se usó <code>knn</code> en el ejemplo anterior (es decir, entrená el clasificador sobre el conjunto train y evaluálo sobre el conjunto test). Tanto <code>knn</code> como <code>clf</code> son clasificadores y heredan los métodos "fit", "predict" y "score" de forma que su uso es casi idéntico. Ventajas del polimorfismo, del que hablamos antes (ver <a href="../../09_Clases_y_Objetos/03_Herencia/#ejercicio-97-polimorfismo-en-acción">Ejercicio 9.7</a>). ¿Qué clasificador dió mejores resultados?</p>
<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()
</code></pre>
<h3 id="ejercicio-1212">Ejercicio 12.12:</h3>
<p>La comparación anterior de los dos clasificadores puede resultar injusta ya que está basada en <em>una</em> partición del conjunto de datos en test y train que podría darle ventaja a uno u otro clasificador, arbitrariamente. </p>
<p>Para evitar esto, repetí 100 veces lo siguiente y calculá el promedio de los scores:</p>
<pre><code>    a) Partición del conjunto original en test y train aleatoriamente (sin fijar la semilla).

    b) Entrenamiento de ambos modelos (knn y clf) con el conjunto train resultante.

    c) Evaluación de ambos clasifcadores (score) con el conjunto test resultante.
</code></pre>
<p>¿Te animás a agregar también un clasificador de <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"><em>Random Forest</em></a>?</p>
<p>Imprimí el promedio de los scores obtenidos y guardá el código en el archivo <code>clasificadores.py</code> para entregar.</p>
<p><a href="../Contenidos.md">Contenidos</a> | <a href="../03_Divide_and_Conquer/">Anterior (3 Divide y reinarás)</a> | <a href="../05_Cierre/">Próximo (5 Cierre de la clase de Ordenamiento)</a></p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentación construida con <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Buscar</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Cerrar</span></button>
            </div>
            <div class="modal-body">
                <p>Desde aquí puede buscar estos documentos. Ingrese sus términos de búsqueda a continuación.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Buscando..." id="mkdocs-search-query" title="Escriba el término de búsqueda aquí">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No se encontraron resultados"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Atajos de teclado</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Cerrar</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Teclas</th>
                    <th>Acción</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Abrir esta ayuda</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Página siguiente</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Página anterior</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Buscar</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
